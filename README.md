# report-spring-2017
Этот репозиторий создан для отчёта перед научным руководителем о текущей деятельности. Проведённые эксперименты, прочитанные статьи, мысли, планы, идеи. 

**Тема преддипломной практики**: Разработка модуля кластеризации запросов и ответов веб-ресурса для выявления бизнес-логики в составе системы обнаружения атак на веб-приложения

**Тема диплома** (сформулированная широко): Автоматическое выделение признаков в сигналах кардиограмм в задаче выявления болезней сердца.

---

Ниже этой шапки свежие записи находятся выше, старые утекают вниз.

**04.03.2017**

Понял, что опечатлся в подсчёте точности. Так что всё обстоит иначе:

- 1D conv net трёхблочной архитектуры (3*[conv+glob_pool+dense+dense]+dense+dense) выдаёт 76.4% точности и 0.66 auc.
- Случайный лес поверх признаков с последнего полносвязного слоя выдаёт 69% точности и 0.60 auc. 

То есть чистая сеть пока умеет классифицировать лучше, чем генерировать признаки. При этом всё это происходит на срезе сигнала длиной 1000, то есть лишь на одном пике (при этом сам пик в произвольном месте). Бейзлайн с Фурье же усредняет признаки по всему сигналу и избавляется от шума (если делать аналогично и брать лишь по 1000, то всего лишь 66.5%). Здесь такое проделать не удаётся.  Возможно, такое усреднее возможно для внутреннего представления.

**27.02.2017**

_Занимался:_

Продолжил экспериментировать с 1D свёрточными сетями на разномасштабных данных. Пробовал изменять архитектуру и прочие вещи, но ничего существенного не добился. Упоминание максимальной точности в 64% в прошлый раз можно считать некорректным с учётом баланса классов. AUC около 0.68. Однако на представлениях ничего хорошего получить не удаётся. Качество хуже самой сетки. При усложнении архитектуры появляется переобучение (видимо, сеть учится определяться конкретных людей). Бросил это направление пока.

Немного поковырял рекуррентные сети. LSTM судя по функции потерь чему-то учится, но на выходе результаты никакие. Пробовал просто классифицировать сеть после 1000 точек сигнала. Как вариант, не классифицировать сигнал, а научить сеть только предсказывать вперёд сигнал. А потом будто бы искать отклонения у больных людей. Смотреть на внутреннее представление пока не пробовал. 

_Прочитал:_

1. [Time-series modeling with undecimated fully convolutional neural networks](https://arxiv.org/abs/1508.00317) (Август 2015):
   * Предлагают использовать аналог полносвязной свёрточной сети (рассказывалась на спецсеминаре по теме сегментации изображений).
   * Говорят, что работает лучше, чем рекурретные сети в задачах классификации и регрессии. Но их эксперименты кажутся несколько сомнительными.
2. [Multi-Scale Convolutional Neural Networks for Time Series Classification](https://arxiv.org/abs/1603.06995) (Март 2016):
   * Это уже упомянутые свёрточные сети, работающие на разных масштабах данных. Предлагается делать несколько входов с разными масштабами данных, на которых работают свёрточные слои, после чего результаты конкатенируются, далее применяются свёртки и полносвязные слои. Также предлагается использовать пулинги разных размеров (у меня же был глобальный пулинг на локальной стадии). Говорят, что обучение фильтров это в некоторой степени обобщение шейплетов.
   * В экспериментах показывают, что такая архитектура лучше обычной свёрточной сети. Далее используя множество классических известных методов для работы с временными рядами (и основанных на расстоянии, и основанных на выделении признаков) и множество небольших датасетов показывают, что где-то их метод лучше (но не везде). Показывают, что по сравнению с каждым методом отдельно их подход чаще всего лучше. Ещё говорят, что их подход лучше в среднем, чем все методы на расстоянии и все методы на выделении признаков, но уступает одному ансамблевому методу.
3. [Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline](https://arxiv.org/abs/1611.06455) (Ноябрь 2016):
   * Ссылаются на 2 упомянутых выше статьи. Учитывают результаты MSCNN (эксперименты на тех же датасетах).
   * Предлагают 3 бейзлайн-архитектуры: обычная сеть с тремя скрытыми слоями и дропаутами, полносвязаная свёрточная сеть с батчнормом и глобальным пулингом на конце, трёхблочный резнет с батчнормом и глобальным пулингом на конце. Объясняют, почему они считают определённые гиперпараметры подходящими (они ведь хотят бейзлайн для всего). 
   * В экспериментах показывают, что на большинстве датасетов один из их подходов справляется лучше всего. 

_Планирую:_

Продолжить работать с рекуррентными сетями и попробовать архитектуры из последней статьи. 



**21.02.2017**

Повторил все эксперименты прошлой половины года на новом датасете (использовал отфильтрованные сигналы). Получилось:

| Признаки                                 | Качество (old) | Качество (new) |
| ---------------------------------------- | -------------- | -------------- |
| Фурье, сингул.числа, статистики          | 75.2%          | 68.3%          |
| Признаки Успенского                      | 77.5%          | 73.4%          |
| Статистики по интервалам                 | 67.7%          | 69.1%          |
| Статистики по QRS                        | 70.7%          | 72.7%          |
| Фурье, сингул.числа, статистики по интервалам | 72.9%          | 69.1%          |
| Фурье по обычным окнам                   | 72.9%          | 64.2%          |
| Фурье по окнам с пиками                  | 73.9%          | 66.9%          |

Это усреднённое по людям качество с подобранным порогом (правда, на той же самой выборке). То есть почти по всем группам признакам получено ухудшение качества. Причины не изучал, но на первый взгляд кажется, будто шума в них больше. Пока продолжил работать со старым датасетом.

Продолжил работать с 1D свёрточными сетями на разномасштабных данных. Поначалу ничего не получалось, но когда сделал нормировку на каждом случайном сэмпле, а не всём сигнале, то сеть стала чему-то учиться. Сама сеть показала около ~~65%~~ (иногда меньше), а вот бустинг поверх предпоследнего слоя ничего хорошего не показал (~~66%~~). Точность не усреднённая по людям, но обучение и валидация на разных людях.

Правда, есть проблема с тем, что выборка не очень большая, поэтому отделять кусок на каждом этапе непросто. Возможно, в этом проблема бустинга поверх скрытого представления (обучающая выборка остаётся той же, на которой училась сетка). 

Казалось бы, такие маленькие свёртки и не должны чему-либо научиться, но при увеличении размера качество не растёт, но переобучение становится более заметным. Попробую немного поиграться с архитектурой и гиперпараметрами, а потом буду пытаться применять следующие подходы (авкодировщик, сеть поверх Фурье и Фурье 2D).

Ещё проверю на новом датасете. Там как-то проще будет обогнать стандартный подход с Фурье...

В файле mscnn.ipynb можно увидеть немного подчищенный код. 

**14.02.2017**

_Просмотрел в последнее время_:

1. Classification of ECG Signal by Using Wavelet Transform and SVM (Zahra Golrizkhatami), 2015:
   * с помощью вейвлетов находят все нужные элементы на кардиограмме (QRS-комплекс) и по ним строят признаки
   * используют датасет MIT-BIH (48 записей, разные болезни сердца
   * средняя точность выявления болезней около 97 процентов


2. ECG Beats Classification Using Mixture of Features (Manab Kumar Das, Samit Ari), 2014:
   * признаки по пикам, фурье и вейвлетам
   * MIT-BIH, при этом тестируют они на тех людях, только на других участках записей
     И другие статьи. В них либо про ручное выделение участков, либо по преобразованию Фурье, вейлетами, фильтрами. Есть статьи про сравнение основных подходов к преобразованиям. Подробно не читал. 

_Чем занимаюсь_:

Экспериментирую с сетями, навеянными [Multi-Scale Convolutional Neural Networks](https://arxiv.org/abs/1603.06995), о которых услышал на хакатоне, где классифицировали EEG (24 канала, а не 1). Казалось бы, здравая мысль брать одновременно сигналы разных длин (один и тот же участок сжатый в разное число раз позволяет в разных масштабах смотреть на сигнал), гонять по ним свёртки и брать от этого глобальный пулинг, чтобы избавиться от каких-либо локальных признаков. И должны получаться обученные находить свойственные заболеваниям места фильтры. Но ничего дельного пока не вышло. 

Дальше планирую пробовать автокодировщики в надежде получить на внутреннем представлении признаки для другого алгоритма. 

Ещё хочется поработать с преобразованиями Фурье, но при этом не усреднять их, делая 1D, а оставить в виде 2D. Тогда можно рассматривать сигнал в виде условно картинки (а это навеяно рассказом Дмитрия Ульянова про перенос стиля для музыки, где одномерный сигнал переводят вот так и работают с таким представлением).

_Что хочу и как вижу:_

Возможно, дело в моих ограниченных представлениях, но мне первым и единственным в голову приходит обучить сеть некоторого подходящего вида (возможно, для классификации, а можно автокодировщик или ещё что угодно на выходе), чтобы использовать внутреннее представление как набор признаков для какого-то классического алгоритма. И показать, что вот такое построение признаков (автоматическое) показывает более высокие финальные результаты, чем другие признаки, не требующие эвристик (например, из преобразования Фурье). 

_Ещё:_

Работаю пока со старым датасетом. Новый посмотрел, частично прогонял старый код по выявлению ИБС. Некоторые эвристики, кажется, ломаются (эвристики ведь). Какие-то результаты падают, какие-то растут (AUC вверх, точность вниз, например). В ближайшее время проделаю нормально и перееду на новый датасет. 

