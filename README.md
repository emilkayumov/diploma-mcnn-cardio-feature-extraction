# report-spring-2017
Этот репозиторий создан для отчёта перед научным руководителем о текущей деятельности. Проведённые эксперименты, прочитанные статьи, мысли, планы, идеи. 

**Тема преддипломной практики**: Разработка модуля кластеризации запросов и ответов веб-ресурса для выявления бизнес-логики в составе системы обнаружения атак на веб-приложения

**Тема диплома** (сформулированная широко): Автоматическое выделение признаков в сигналах кардиограмм в задаче выявления болезней сердца.

---

Ниже этой шапки свежие записи находятся выше, старые утекают вниз.

**10.04.2017**

Попробовал сравнить внутренние состояния. Запускал t-SNE и PCA.

1. Если взять и для каждого человека усреднить внутренние состояния после обработки сетью, то можно получиться следующую картинку:![1](/Users/ekayumov/Yandex.Disk.localized/Cardio/report-spring-2017/images/1.png)

   Не то чтобы хорошо, но некую сгруппированность по классам увидеть можно.

2. Если взять по 2 человека из 2 классов и у каждого взять по 15 сигналов, по которым усреднить внутреннее состояние, то получится следующее:![2](/Users/ekayumov/Yandex.Disk.localized/Cardio/report-spring-2017/images/2.png)

   Есть сгруппированность по сигналам отдельных людей (разные цвета), но нет разделимости по классам.

**28.03.2017**

1. Попробовал аугментацию (растяжение и сжатие участка), но не заметил никаких улучшений (ни в стабилизации при обучении, ни в качестве на отложенной выборке).
2. Во всём процессе экспериментирования разделил кардиограммы отдельных людей. Теперь при построении батча или при построении случайной выборки для тестирования сначала выбирается человек, потом только кардиограмма этого человека, далее, если необходимо, вырезается участок. Это позволило при генерировании случайной подвыборки получать выборку усреднённую по людям (как и результаты), а не с преобладанием людей с большим количеством замеров. При обучении сети это позволило стабилизировать процесс обучения, хотя и заметно замедлило его. 
3. Работаю со второй версией данных, раз уж первая была почищена и как-то пересклеена. Поэтому все результаты ниже по качеству.
4. Гипотеза о том, что преобразованный датасет сеткой нужно ещё раз делить на обучение/тестирование, иначе будет переобучение, не подвтердилась. Результат тот же. 
5. Считать максимальную точность по той же самой выборке нечестно, но отделять ещё часть выборки для оценки порога...

Сеть обучалась примерно на половине данных, другая половина использовалась либо для тестирования целиком, либо делилась отдельно. Результаты ориентировочные, потому что каждый эксперимент, по-хорошему, надо проводить отдельно и для различных разбиений (сеть обученная на половине данных, естественно, хуже, чем на 80%, если брать 5 фолдов, но тогда не провести другие испытания). 

1. На случайных участках:

   |              | Сеть | Преобразование сетью | Фурье |
   | ------------ | ---- | -------------------- | ----- |
   | AUC          | 0.73 | 0.72                 | 0.71  |
   | Max accuracy | 0.67 | 0.67                 | 0.66  |

2. Усреднение результатов по участкам кардиограмм (обучение всё так же на участках):

   |              | Сеть | Преобразование сетью | Фурье |
   | ------------ | ---- | -------------------- | ----- |
   | AUC          | 0.79 | 0.80                 | 0.76  |
   | Max accuracy | 0.73 | 0.74                 | 0.72  |

3. Усреднение представлений до обучению модели:

   |              | Преобразование сетью | Фурье |
   | ------------ | -------------------- | ----- |
   | AUC          | 0.69                 | -     |
   | Max accuracy | 0.69                 | 0.64  |

   (Фурье взят из прошлых экспериментов). Максимальная точность посчитана не очень честно, так как внутри каждого фолда отдельно. 

**13.03.2017**

_Что имею:_

* Чистая сеть выдаёт около 75% точности. Тестовая выборка строилась по другим людям, каждый объект выборки это у случайно выбранного человека взят случайный кусок кардиограммы длиной в 1000.
* Случайный лес на 150 признаках с последнего слоя той же сети даёт около 67%. Одна из вероятных проблем в формировании выборки, так как в условиях малого количества данных в обучении леса используются те же люди, на которых училась сеть. В обучении используется 10k объектов выбранных случайно, аналогично предыдущему пункту.
* Если для каждой кардиограммы тестовой выборки пройтись окном, прогнать через сеть и усреднить все вероятности каждого сигнала , то получается около 83% точности! Такого на этих данных я не достигал, хотя до этого валидация была устроена иначе.
* Если аналогично предыдущему пункту усреднить признаки с последнего слоя сети, а потом подать в случайный лес, то 69%.
* Бейзлайн со случайным лесом на коэффициентах Фурье на кусках длиной в 1000 (аналогично работе сети в 1 пункте, что довольно шумно для качественной классификации) дают около 66%.
* Если усреднить предсказания по коэффициентам Фурье аналогично 3 пункту, то получится около 80%.
* Если усредить коэффициенты Фурье с окнами, аналогичными 4 пункту, а только потом обучать, то должно получаться по старым экспериментам около 73%. 

То есть чистая сеть на кусочках лучше случайного леса на последнем слое сети, который показывает почти такое же качество, как Фурье. Если усреднять предсказания по кускам внутри сигнала, то сеть немного лучше Фурье и оба заметно лучше случайного леса на последнем слое. Случайный лес на усреднённых Фурье немного лучше усреднённого последнего слоя. 

**04.03.2017**

Понял, что опечатлся в подсчёте точности. Так что всё обстоит иначе:

- 1D conv net трёхблочной архитектуры (3*[conv+glob_pool+dense+dense]+dense+dense) выдаёт 76.4% точности и 0.66 auc.
- Случайный лес поверх признаков с последнего полносвязного слоя выдаёт 69% точности и 0.60 auc. 

То есть чистая сеть пока умеет классифицировать лучше, чем генерировать признаки. При этом всё это происходит на срезе сигнала длиной 1000, то есть лишь на одном пике (при этом сам пик в произвольном месте). Бейзлайн с Фурье же усредняет признаки по всему сигналу и избавляется от шума (если делать аналогично и брать лишь по 1000, то всего лишь 66.5%). Здесь такое проделать не удаётся.  Возможно, такое усреднее возможно для внутреннего представления.

**27.02.2017**

_Занимался:_

Продолжил экспериментировать с 1D свёрточными сетями на разномасштабных данных. Пробовал изменять архитектуру и прочие вещи, но ничего существенного не добился. Упоминание максимальной точности в 64% в прошлый раз можно считать некорректным с учётом баланса классов. AUC около 0.68. Однако на представлениях ничего хорошего получить не удаётся. Качество хуже самой сетки. При усложнении архитектуры появляется переобучение (видимо, сеть учится определяться конкретных людей). Бросил это направление пока.

Немного поковырял рекуррентные сети. LSTM судя по функции потерь чему-то учится, но на выходе результаты никакие. Пробовал просто классифицировать сеть после 1000 точек сигнала. Как вариант, не классифицировать сигнал, а научить сеть только предсказывать вперёд сигнал. А потом будто бы искать отклонения у больных людей. Смотреть на внутреннее представление пока не пробовал. 

_Прочитал:_

1. [Time-series modeling with undecimated fully convolutional neural networks](https://arxiv.org/abs/1508.00317) (Август 2015):
   * Предлагают использовать аналог полносвязной свёрточной сети (рассказывалась на спецсеминаре по теме сегментации изображений).
   * Говорят, что работает лучше, чем рекурретные сети в задачах классификации и регрессии. Но их эксперименты кажутся несколько сомнительными.
2. [Multi-Scale Convolutional Neural Networks for Time Series Classification](https://arxiv.org/abs/1603.06995) (Март 2016):
   * Это уже упомянутые свёрточные сети, работающие на разных масштабах данных. Предлагается делать несколько входов с разными масштабами данных, на которых работают свёрточные слои, после чего результаты конкатенируются, далее применяются свёртки и полносвязные слои. Также предлагается использовать пулинги разных размеров (у меня же был глобальный пулинг на локальной стадии). Говорят, что обучение фильтров это в некоторой степени обобщение шейплетов.
   * В экспериментах показывают, что такая архитектура лучше обычной свёрточной сети. Далее используя множество классических известных методов для работы с временными рядами (и основанных на расстоянии, и основанных на выделении признаков) и множество небольших датасетов показывают, что где-то их метод лучше (но не везде). Показывают, что по сравнению с каждым методом отдельно их подход чаще всего лучше. Ещё говорят, что их подход лучше в среднем, чем все методы на расстоянии и все методы на выделении признаков, но уступает одному ансамблевому методу.
3. [Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline](https://arxiv.org/abs/1611.06455) (Ноябрь 2016):
   * Ссылаются на 2 упомянутых выше статьи. Учитывают результаты MSCNN (эксперименты на тех же датасетах).
   * Предлагают 3 бейзлайн-архитектуры: обычная сеть с тремя скрытыми слоями и дропаутами, полносвязаная свёрточная сеть с батчнормом и глобальным пулингом на конце, трёхблочный резнет с батчнормом и глобальным пулингом на конце. Объясняют, почему они считают определённые гиперпараметры подходящими (они ведь хотят бейзлайн для всего). 
   * В экспериментах показывают, что на большинстве датасетов один из их подходов справляется лучше всего. 

_Планирую:_

Продолжить работать с рекуррентными сетями и попробовать архитектуры из последней статьи. 



**21.02.2017**

Повторил все эксперименты прошлой половины года на новом датасете (использовал отфильтрованные сигналы). Получилось:

| Признаки                                 | Качество (old) | Качество (new) |
| ---------------------------------------- | -------------- | -------------- |
| Фурье, сингул.числа, статистики          | 75.2%          | 68.3%          |
| Признаки Успенского                      | 77.5%          | 73.4%          |
| Статистики по интервалам                 | 67.7%          | 69.1%          |
| Статистики по QRS                        | 70.7%          | 72.7%          |
| Фурье, сингул.числа, статистики по интервалам | 72.9%          | 69.1%          |
| Фурье по обычным окнам                   | 72.9%          | 64.2%          |
| Фурье по окнам с пиками                  | 73.9%          | 66.9%          |

Это усреднённое по людям качество с подобранным порогом (правда, на той же самой выборке). То есть почти по всем группам признакам получено ухудшение качества. Причины не изучал, но на первый взгляд кажется, будто шума в них больше. Пока продолжил работать со старым датасетом.

Продолжил работать с 1D свёрточными сетями на разномасштабных данных. Поначалу ничего не получалось, но когда сделал нормировку на каждом случайном сэмпле, а не всём сигнале, то сеть стала чему-то учиться. Сама сеть показала около ~~65%~~ (иногда меньше), а вот бустинг поверх предпоследнего слоя ничего хорошего не показал (~~66%~~). Точность не усреднённая по людям, но обучение и валидация на разных людях.

Правда, есть проблема с тем, что выборка не очень большая, поэтому отделять кусок на каждом этапе непросто. Возможно, в этом проблема бустинга поверх скрытого представления (обучающая выборка остаётся той же, на которой училась сетка). 

Казалось бы, такие маленькие свёртки и не должны чему-либо научиться, но при увеличении размера качество не растёт, но переобучение становится более заметным. Попробую немного поиграться с архитектурой и гиперпараметрами, а потом буду пытаться применять следующие подходы (авкодировщик, сеть поверх Фурье и Фурье 2D).

Ещё проверю на новом датасете. Там как-то проще будет обогнать стандартный подход с Фурье...

В файле mscnn.ipynb можно увидеть немного подчищенный код. 

**14.02.2017**

_Просмотрел в последнее время_:

1. Classification of ECG Signal by Using Wavelet Transform and SVM (Zahra Golrizkhatami), 2015:
   * с помощью вейвлетов находят все нужные элементы на кардиограмме (QRS-комплекс) и по ним строят признаки
   * используют датасет MIT-BIH (48 записей, разные болезни сердца
   * средняя точность выявления болезней около 97 процентов


2. ECG Beats Classification Using Mixture of Features (Manab Kumar Das, Samit Ari), 2014:
   * признаки по пикам, фурье и вейвлетам
   * MIT-BIH, при этом тестируют они на тех людях, только на других участках записей
     И другие статьи. В них либо про ручное выделение участков, либо по преобразованию Фурье, вейлетами, фильтрами. Есть статьи про сравнение основных подходов к преобразованиям. Подробно не читал. 

_Чем занимаюсь_:

Экспериментирую с сетями, навеянными [Multi-Scale Convolutional Neural Networks](https://arxiv.org/abs/1603.06995), о которых услышал на хакатоне, где классифицировали EEG (24 канала, а не 1). Казалось бы, здравая мысль брать одновременно сигналы разных длин (один и тот же участок сжатый в разное число раз позволяет в разных масштабах смотреть на сигнал), гонять по ним свёртки и брать от этого глобальный пулинг, чтобы избавиться от каких-либо локальных признаков. И должны получаться обученные находить свойственные заболеваниям места фильтры. Но ничего дельного пока не вышло. 

Дальше планирую пробовать автокодировщики в надежде получить на внутреннем представлении признаки для другого алгоритма. 

Ещё хочется поработать с преобразованиями Фурье, но при этом не усреднять их, делая 1D, а оставить в виде 2D. Тогда можно рассматривать сигнал в виде условно картинки (а это навеяно рассказом Дмитрия Ульянова про перенос стиля для музыки, где одномерный сигнал переводят вот так и работают с таким представлением).

_Что хочу и как вижу:_

Возможно, дело в моих ограниченных представлениях, но мне первым и единственным в голову приходит обучить сеть некоторого подходящего вида (возможно, для классификации, а можно автокодировщик или ещё что угодно на выходе), чтобы использовать внутреннее представление как набор признаков для какого-то классического алгоритма. И показать, что вот такое построение признаков (автоматическое) показывает более высокие финальные результаты, чем другие признаки, не требующие эвристик (например, из преобразования Фурье). 

_Ещё:_

Работаю пока со старым датасетом. Новый посмотрел, частично прогонял старый код по выявлению ИБС. Некоторые эвристики, кажется, ломаются (эвристики ведь). Какие-то результаты падают, какие-то растут (AUC вверх, точность вниз, например). В ближайшее время проделаю нормально и перееду на новый датасет. 

